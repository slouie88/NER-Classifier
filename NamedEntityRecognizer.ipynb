{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Implementation\n",
    "Below is the code used to implement a Named Entity Recognizer (NER) application in Python using the CRFsuite library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 0.21.2\n",
      "Libraries succesfully loaded!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import io\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "import scipy\n",
    "import codecs\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "print('sklearn version:', sklearn.__version__)\n",
    "print('Libraries succesfully loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features_train(sent, feature_func):\n",
    "    sentences, labels = zip(*sent)\n",
    "    sentences = list(sentences)\n",
    "    pos_tagged = pos_tag(sentences)\n",
    "    return [feature_func(pos_tagged, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2features(sent, feature_func):\n",
    "    sentences = [i[0] for i in sent]\n",
    "    pos_tagged = pos_tag(sentences)\n",
    "    return [feature_func(pos_tagged, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [s[-1] for s in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [s[0] for s in sent]\n",
    "\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly.\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(y_true)\n",
    "    y_pred_combined = lb.transform(y_pred)\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "            \n",
    "def word2simple_features(sent, i):\n",
    "    '''\n",
    "    Performs feature extraction on the given sentence input.\n",
    "    Used as a mapping function by the above functions that convert sentences to features.\n",
    "    '''\n",
    "    word = sent[i][0]\n",
    "    pos_tag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, # This feature is constant for all words.\n",
    "        'word.lower()': word.lower(), # This feature is the word, ignoring case.\n",
    "        'word[-2:]': word[-2:], # This feature is the last two characters of the word (i.e. the suffix).\n",
    "        'word[-3:]': word[-3:], # This feature is the last three characters of the word (also the suffix).\n",
    "        'word.isupper()': word.isupper(), # This feature is a binary indicator of whether the word is capitalized.\n",
    "        'word.istitle()': word.istitle(), # This feature is a binary indicator of whether the word is titled.\n",
    "        'word.isdigit()': word.isdigit(), # This feature is a binary indicator of whether the word is numeric or not.\n",
    "        'pos_tag': pos_tag\n",
    "    }\n",
    "    if i == 0:\n",
    "        features['BOS'] = True # Mark the beginning of sentence.\n",
    "    \n",
    "    if i > 0:\n",
    "        prev_word = sent[i-1][0]\n",
    "        prev_pos_tag = sent[i-1][1]\n",
    "        features.update({\n",
    "            'prev_word.lower()': prev_word.lower(),\n",
    "            'prev_word.isupper()': prev_word.isupper(),\n",
    "            'prev_word.istitle()': prev_word.istitle(),\n",
    "            'prev_pos_tag': prev_pos_tag\n",
    "        })\n",
    "        \n",
    "    if i == len(sent)-1:\n",
    "        features['EOS'] = True # Mark the end of sentence.\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        next_word = sent[i+1][0]\n",
    "        next_pos_tag = sent[i+1][1]\n",
    "        features.update({\n",
    "            'next_word.lower()': next_word.lower(),\n",
    "            'next_word.isupper()': next_word.isupper(),\n",
    "            'next_word.istitle()': next_word.istitle(),\n",
    "            'next_pos_tag': next_pos_tag\n",
    "        })       \n",
    "\n",
    "    return features\n",
    "\n",
    "# load data and preprocess\n",
    "def extract_data(path):\n",
    "    \"\"\"\n",
    "    Extracting data from train file or test file. \n",
    "    path - the path of the file to extract\n",
    "    \n",
    "    return:\n",
    "        res - a list of sentences, each sentence is a\n",
    "              a list of tuples. For train file, each tuple\n",
    "              contains token and label. For test file, each\n",
    "              tuple only contains token.\n",
    "        ids - a list of ids for the corresponding token. This\n",
    "              is mainly for a Kaggle submission.\n",
    "    \"\"\"\n",
    "    file = io.open(path, mode=\"r\", encoding=\"utf-8\")\n",
    "    next(file)\n",
    "    res = []\n",
    "    ids = []\n",
    "    sent = []\n",
    "    for line in file:\n",
    "        if line != '\\n':\n",
    "            # Each line contains the position ID, the token, and (for the training set) the label.\n",
    "            parts = line.strip().split(' ')\n",
    "            sent.append(tuple(parts[1:]))\n",
    "            ids.append(parts[0])\n",
    "        else:\n",
    "            res.append(sent)\n",
    "            sent = []\n",
    "           \n",
    "    return res, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test data loaded succesfully!\n",
      "Feature Extraction done!\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word.lower()': 'también',\n",
       "  'word[-2:]': 'én',\n",
       "  'word[-3:]': 'ién',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'BOS': True,\n",
       "  'next_word.lower()': 'el',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'el',\n",
       "  'word[-2:]': 'el',\n",
       "  'word[-3:]': 'el',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': 'también',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': True,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': 'secretario',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'secretario',\n",
       "  'word[-2:]': 'io',\n",
       "  'word[-3:]': 'rio',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': 'el',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'general',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'JJ'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'general',\n",
       "  'word[-2:]': 'al',\n",
       "  'word[-3:]': 'ral',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'JJ',\n",
       "  'prev_word.lower()': 'secretario',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'de',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'de',\n",
       "  'word[-2:]': 'de',\n",
       "  'word[-3:]': 'de',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'general',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'JJ',\n",
       "  'next_word.lower()': 'la',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'la',\n",
       "  'word[-2:]': 'la',\n",
       "  'word[-3:]': 'la',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'de',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'asociación',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': True,\n",
       "  'next_pos_tag': 'NNP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'asociación',\n",
       "  'word[-2:]': 'ón',\n",
       "  'word[-3:]': 'ión',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'prev_word.lower()': 'la',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'española',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': True,\n",
       "  'next_pos_tag': 'NNP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'española',\n",
       "  'word[-2:]': 'la',\n",
       "  'word[-3:]': 'ola',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'prev_word.lower()': 'asociación',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': True,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': 'de',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'de',\n",
       "  'word[-2:]': 'de',\n",
       "  'word[-3:]': 'de',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'española',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': True,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': 'operadores',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': True,\n",
       "  'next_pos_tag': 'NNP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'operadores',\n",
       "  'word[-2:]': 'es',\n",
       "  'word[-3:]': 'res',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'prev_word.lower()': 'de',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'de',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'de',\n",
       "  'word[-2:]': 'de',\n",
       "  'word[-3:]': 'de',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'operadores',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': True,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': 'productos',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': True,\n",
       "  'next_pos_tag': 'NNP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'productos',\n",
       "  'word[-2:]': 'os',\n",
       "  'word[-3:]': 'tos',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'prev_word.lower()': 'de',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'petrolíferos',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': True,\n",
       "  'next_pos_tag': 'NNP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'petrolíferos',\n",
       "  'word[-2:]': 'os',\n",
       "  'word[-3:]': 'ros',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'prev_word.lower()': 'productos',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': True,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': ',',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': ','},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': ',',\n",
       "  'word[-2:]': ',',\n",
       "  'word[-3:]': ',',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': ',',\n",
       "  'prev_word.lower()': 'petrolíferos',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': True,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': 'aurelio',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': True,\n",
       "  'next_pos_tag': 'NNP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'aurelio',\n",
       "  'word[-2:]': 'io',\n",
       "  'word[-3:]': 'lio',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'prev_word.lower()': ',',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': ',',\n",
       "  'next_word.lower()': 'ayala',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': True,\n",
       "  'next_pos_tag': 'NNP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'ayala',\n",
       "  'word[-2:]': 'la',\n",
       "  'word[-3:]': 'ala',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'prev_word.lower()': 'aurelio',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': True,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': ',',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': ','},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': ',',\n",
       "  'word[-2:]': ',',\n",
       "  'word[-3:]': ',',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': ',',\n",
       "  'prev_word.lower()': 'ayala',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': True,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': 'ha',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'ha',\n",
       "  'word[-2:]': 'ha',\n",
       "  'word[-3:]': 'ha',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': ',',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': ',',\n",
       "  'next_word.lower()': 'negado',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'negado',\n",
       "  'word[-2:]': 'do',\n",
       "  'word[-3:]': 'ado',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': 'ha',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'la',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'la',\n",
       "  'word[-2:]': 'la',\n",
       "  'word[-3:]': 'la',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'negado',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'existencia',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'existencia',\n",
       "  'word[-2:]': 'ia',\n",
       "  'word[-3:]': 'cia',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'la',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'de',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'de',\n",
       "  'word[-2:]': 'de',\n",
       "  'word[-3:]': 'de',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'existencia',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'cualquier',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'cualquier',\n",
       "  'word[-2:]': 'er',\n",
       "  'word[-3:]': 'ier',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'de',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'tipo',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'tipo',\n",
       "  'word[-2:]': 'po',\n",
       "  'word[-3:]': 'ipo',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'cualquier',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'de',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'de',\n",
       "  'word[-2:]': 'de',\n",
       "  'word[-3:]': 'de',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'tipo',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'acuerdos',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'acuerdos',\n",
       "  'word[-2:]': 'os',\n",
       "  'word[-3:]': 'dos',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'de',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'sobre',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'sobre',\n",
       "  'word[-2:]': 're',\n",
       "  'word[-3:]': 'bre',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'acuerdos',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'los',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'los',\n",
       "  'word[-2:]': 'os',\n",
       "  'word[-3:]': 'los',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'sobre',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'precios',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NNS'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'precios',\n",
       "  'word[-2:]': 'os',\n",
       "  'word[-3:]': 'ios',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNS',\n",
       "  'prev_word.lower()': 'los',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': ',',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': ','},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': ',',\n",
       "  'word[-2:]': ',',\n",
       "  'word[-3:]': ',',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': ',',\n",
       "  'prev_word.lower()': 'precios',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NNS',\n",
       "  'next_word.lower()': 'afirmando',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'afirmando',\n",
       "  'word[-2:]': 'do',\n",
       "  'word[-3:]': 'ndo',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': ',',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': ',',\n",
       "  'next_word.lower()': 'que',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'que',\n",
       "  'word[-2:]': 'ue',\n",
       "  'word[-3:]': 'que',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': 'afirmando',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'únicamente',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NNP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'únicamente',\n",
       "  'word[-2:]': 'te',\n",
       "  'word[-3:]': 'nte',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNP',\n",
       "  'prev_word.lower()': 'que',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'es',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'VBZ'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'es',\n",
       "  'word[-2:]': 'es',\n",
       "  'word[-3:]': 'es',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'VBZ',\n",
       "  'prev_word.lower()': 'únicamente',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NNP',\n",
       "  'next_word.lower()': 'la',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'la',\n",
       "  'word[-2:]': 'la',\n",
       "  'word[-3:]': 'la',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'es',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'VBZ',\n",
       "  'next_word.lower()': 'cotización',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'cotización',\n",
       "  'word[-2:]': 'ón',\n",
       "  'word[-3:]': 'ión',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'la',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'internacional',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'JJ'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'internacional',\n",
       "  'word[-2:]': 'al',\n",
       "  'word[-3:]': 'nal',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'JJ',\n",
       "  'prev_word.lower()': 'cotización',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'la',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'la',\n",
       "  'word[-2:]': 'la',\n",
       "  'word[-3:]': 'la',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': 'internacional',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'JJ',\n",
       "  'next_word.lower()': 'que',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'que',\n",
       "  'word[-2:]': 'ue',\n",
       "  'word[-3:]': 'que',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'la',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'pone',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'pone',\n",
       "  'word[-2:]': 'ne',\n",
       "  'word[-3:]': 'one',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': 'que',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'de',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'de',\n",
       "  'word[-2:]': 'de',\n",
       "  'word[-3:]': 'de',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'pone',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'acuerdo',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'FW'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'acuerdo',\n",
       "  'word[-2:]': 'do',\n",
       "  'word[-3:]': 'rdo',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'FW',\n",
       "  'prev_word.lower()': 'de',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'a',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'DT'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'a',\n",
       "  'word[-2:]': 'a',\n",
       "  'word[-3:]': 'a',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'DT',\n",
       "  'prev_word.lower()': 'acuerdo',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'FW',\n",
       "  'next_word.lower()': 'todos',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'todos',\n",
       "  'word[-2:]': 'os',\n",
       "  'word[-3:]': 'dos',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': 'a',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'DT',\n",
       "  'next_word.lower()': 'los',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'los',\n",
       "  'word[-2:]': 'os',\n",
       "  'word[-3:]': 'los',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NN',\n",
       "  'prev_word.lower()': 'todos',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': 'países',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': 'NNS'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'países',\n",
       "  'word[-2:]': 'es',\n",
       "  'word[-3:]': 'ses',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': 'NNS',\n",
       "  'prev_word.lower()': 'los',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NN',\n",
       "  'next_word.lower()': '.',\n",
       "  'next_word.isupper()': False,\n",
       "  'next_word.istitle()': False,\n",
       "  'next_pos_tag': '.'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': '.',\n",
       "  'word[-2:]': '.',\n",
       "  'word[-3:]': '.',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'pos_tag': '.',\n",
       "  'prev_word.lower()': 'países',\n",
       "  'prev_word.isupper()': False,\n",
       "  'prev_word.istitle()': False,\n",
       "  'prev_pos_tag': 'NNS',\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Load train and test data\n",
    "train_data, train_ids = extract_data('train')\n",
    "test_data, test_ids = extract_data('test')\n",
    "\n",
    "# Load true labels for test data\n",
    "test_labels = list(pd.read_csv('test_ground_truth').loc[:, 'label'])\n",
    "\n",
    "print('Train and Test data loaded succesfully!')\n",
    "\n",
    "# Feature extraction using the word2simple_features function\n",
    "train_features = [sent2features_train(s, feature_func=word2simple_features) for s in train_data]\n",
    "train_labels = [sent2labels(s) for s in train_data]\n",
    "test_features = [sent2features(s, feature_func=word2simple_features) for s in test_data]\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(train_features, train_labels):\n",
    "    trainer.append(xseq, yseq)\n",
    "print('Feature Extraction done!')    \n",
    "\n",
    "# Explore the extracted features    \n",
    "sent2features_train(train_data[0], word2simple_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the model parameters\n",
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to training algorithm to pa as it seems to yield better results given experimentation using the data.\n",
    "trainer.select('pa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    \n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done :)\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('ner-esp.model')\n",
    "\n",
    "print('Training done :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.82      0.82      0.82      2039\n",
      "       I-LOC       0.72      0.78      0.75       702\n",
      "      B-MISC       0.62      0.69      0.66       786\n",
      "      I-MISC       0.59      0.72      0.65      1029\n",
      "       B-ORG       0.84      0.87      0.86      3123\n",
      "       I-ORG       0.85      0.81      0.83      2313\n",
      "       B-PER       0.90      0.91      0.91      1881\n",
      "       I-PER       0.94      0.94      0.94      1627\n",
      "\n",
      "   micro avg       0.82      0.84      0.83     13500\n",
      "   macro avg       0.79      0.82      0.80     13500\n",
      "weighted avg       0.82      0.84      0.83     13500\n",
      " samples avg       0.10      0.10      0.10     13500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('ner-esp.model')\n",
    "test_pred = [tagger.tag(xseq) for xseq in test_features]\n",
    "test_pred = [s for w in test_pred for s in w]\n",
    "\n",
    "# Print evaluation\n",
    "print(bio_classification_report(test_pred, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 {'num': 100, 'scores': {}, 'loss': 2098.923487, 'feature_norm': 65.791975, 'time': 0.4}\n"
     ]
    }
   ],
   "source": [
    "print(len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check what the classifier has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-ORG  -> I-ORG   1.951016\n",
      "B-ORG  -> I-ORG   1.909189\n",
      "I-MISC -> I-MISC  1.701659\n",
      "B-MISC -> I-MISC  1.554546\n",
      "I-LOC  -> I-LOC   1.478325\n",
      "B-LOC  -> I-LOC   1.472591\n",
      "B-PER  -> I-PER   1.404586\n",
      "I-PER  -> I-PER   1.315277\n",
      "O      -> B-ORG   1.136446\n",
      "O      -> B-MISC  1.097690\n",
      "O      -> O       1.093353\n",
      "O      -> B-PER   0.893465\n",
      "O      -> B-LOC   0.707388\n",
      "I-PER  -> B-LOC   0.210940\n",
      "I-MISC -> B-MISC  0.165571\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-LOC  -> I-ORG   -0.390828\n",
      "B-ORG  -> I-LOC   -0.395795\n",
      "I-ORG  -> I-MISC  -0.398521\n",
      "I-PER  -> I-MISC  -0.409148\n",
      "B-ORG  -> B-ORG   -0.418304\n",
      "I-LOC  -> B-PER   -0.423404\n",
      "B-MISC -> B-MISC  -0.430383\n",
      "I-MISC -> I-LOC   -0.435844\n",
      "I-ORG  -> B-LOC   -0.451822\n",
      "I-PER  -> B-MISC  -0.539836\n",
      "I-ORG  -> I-LOC   -0.601203\n",
      "O      -> I-ORG   -0.910523\n",
      "O      -> I-MISC  -0.983119\n",
      "O      -> I-PER   -1.003715\n",
      "O      -> I-LOC   -1.108540\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the state features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "2.284351 B-ORG  word.lower():efe-cantabria\n",
      "1.897555 B-ORG  word.lower():petrobras\n",
      "1.816511 B-ORG  word.lower():psoe-progresistas\n",
      "1.811980 B-ORG  word.lower():xfera\n",
      "1.623314 I-PER  prev_word.lower():antoñete\n",
      "1.539890 B-LOC  word.lower():líbano\n",
      "1.525887 B-LOC  prev_word.lower():celebrarán\n",
      "1.505443 B-ORG  word.lower():terra\n",
      "1.489606 I-ORG  prev_word.lower():bt\n",
      "1.410677 B-ORG  word.lower():esquerra\n",
      "1.401450 B-ORG  word.lower():eu-ecologista\n",
      "1.394640 B-ORG  word.lower():coag-extremadura\n",
      "1.381444 B-PER  word.lower():franca\n",
      "1.380736 I-ORG  prev_word.lower():l\n",
      "1.356953 B-ORG  word.lower():telefónica\n",
      "1.350667 O      word.lower():y\n",
      "1.335575 B-ORG  prev_word.lower():mayorista\n",
      "1.331495 I-ORG  prev_word.lower():ag\n",
      "1.319324 B-ORG  word.lower():cámara\n",
      "1.314306 B-ORG  word.lower():amena\n",
      "\n",
      "Top negative:\n",
      "-0.683210 O      prev_word.lower():de\n",
      "-0.685269 O      word[-3:]:LOS\n",
      "-0.685784 O      prev_word.lower():cantidad\n",
      "-0.687172 I-PER  word[-3:]:ico\n",
      "-0.730285 O      word.lower():061\n",
      "-0.733810 B-LOC  word[-3:]:la\n",
      "-0.736947 O      word[-3:]:sil\n",
      "-0.749698 O      prev_word.lower():coi\n",
      "-0.757003 B-PER  prev_word.lower():del\n",
      "-0.790290 I-PER  prev_word.lower():san\n",
      "-0.803557 O      word.lower():parlamento\n",
      "-0.809202 O      word.lower():bosque\n",
      "-0.810962 B-LOC  prev_pos_tag:NNS\n",
      "-0.852343 I-ORG  bias\n",
      "-0.911693 O      prev_word.lower():eses&s\n",
      "-1.021208 O      prev_word.lower():españolas\n",
      "-1.144854 O      word[-2:]:om\n",
      "-1.501248 O      word.isupper()\n",
      "-1.502275 O      prev_word.lower():celebrarán\n",
      "-1.954561 O      word.istitle()\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
